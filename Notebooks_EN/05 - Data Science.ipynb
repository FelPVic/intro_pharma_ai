{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science - Toxicological Predictions\n",
    "\n",
    "\n",
    "---\n",
    "### In this lesson you'll learn:\n",
    "\n",
    "\n",
    "- how to train a SVM.\n",
    "- why it is necessary to scale variables.\n",
    "- how to train a random forest model.\n",
    "- about Y-scrambling and the necessity of train/test splits.\n",
    "- how to split data into a training set and test set.\n",
    "---\n",
    "\n",
    "Today you will learn some basics of data science and machine learning. These will also be relevant for training neural networks. \n",
    "As an example, we will build models to detect the toxicological concern of molecules.\n",
    "In the specific example, we are interested in measuring the **mitochondrial membrane potential** (MMP). This is used as an indicator of the overall health of the cell \\[1\\].\n",
    "\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/326685180/figure/fig4/AS:654070805172233@1532954040230/assay-of-a549-cells-mitochondrial-membrane-potential-with-Jc-1-staining-method-Notes.png\" width=400 height=200 />\n",
    "\n",
    "<center>Example of an MMP assay.<br> <i> Source: Liao et al.[2] licensed under CC-BY-NC</i></center>\n",
    "\n",
    "\n",
    "The data come from the Tox21 Challenge dataset. This competition was about predicting the toxicological properties of molecules. For this purpose, the measurements for a total of twelve assays were made available. For the time being, we focus on only one assay and also do not use the entire data set, but only about 2000 molecules. \n",
    "\n",
    "\n",
    "##### But before that, we will look at the effect of variable scaling by means of an example.\n",
    "\n",
    "---\n",
    "**References:**\n",
    "<br>\n",
    "<br>\n",
    "\\[1\\] Sakamuru, S., Attene-Ramos, M. S., & Xia, M. (2016). Mitochondrial membrane potential assay. In High-throughput screening assays in toxicology (pp. 17-22). Humana Press, New York, NY. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5375165/\n",
    "<br>\n",
    "<br>\n",
    "\\[2\\] Liao, C., Xu, D., Liu, X., Fang, Y., Yi, J., Li, X., & Guo, B. (2018). Iridium (III) complex-loaded liposomes as a drug delivery system for lung cancer through mitochondrial dysfunction. International Journal of Nanomedicine, 13, 4417."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "!pip install rdkit==2022.3.4\n",
    "!pip install searborn\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from rdkit.Chem.Lipinski import * \n",
    "from rdkit.Chem.rdMolDescriptors import CalcExactMolWt, CalcTPSA\n",
    "from rdkit.Chem.Crippen import MolLogP, MolMR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as  sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "if 'google.colab' in sys.modules: # checks whether the notebook runs on collab\n",
    "  !wget https://raw.githubusercontent.com/kochgroup/intro_pharma_ai/main/utils/utils.py\n",
    "  %run utils.py\n",
    "else:\n",
    "  %run ../utils/utils.py # loads prewritten function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    "The scaling of variables can be critical to the success of machine learning models. Scaling variables means that we change the scale of a variable's values. More specifically, we want all variables to use the same scale. \n",
    "\n",
    "For example, the value of a house in € often ranges from 50,000 to several million. However, the area of the house is probably only between 10 and several hundred square meters. The values that the price can take are much larger than those of the area. \n",
    "\n",
    "For some algorithms based on distances or gradients, this can be a problem because the scale of the variable for that variable has a direct impact on the importance of the variable.\n",
    "\n",
    "Variables with a larger scale are given more importance, even if the scale is arbitrary. One could also express the price of a house in 1000€ (50,000 becomes 50). The scale changes, but not the actual variable.\n",
    "\n",
    "To avoid this effect, we scale variables to uniform sizes.\n",
    "For example, **MinMax scaling** scales all values between '0' and '1'. \n",
    "\n",
    "In the following example you can see the influence scaling can have on a Support Vector Machine."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you load the data using Python. \n",
    "\n",
    "___\n",
    "**Datatypes:**\n",
    "<br> <br>\n",
    "There are many different formats in which data is stored. Probably the most commonly used is the `comma separated value` format. This can be recognized by the abbreviation `.csv` at the end of a file. <div style=\"float: right;\"><img  src=\"https://images.freeimages.com/images/large-previews/7f6/tab-key-1243535.jpg\" width=150 height=100 /><center>freeimages.com: T. Al Nakib</center></div>\n",
    "\n",
    "As the name implies, the individual values are separated by a comma. Values that belong in the same row are written in the same line and columns are separated by the comma. Other file formats that are often used are text files `.txt`. Here it is not possible to conclude directly from the extension how the structure is built.\n",
    "But often the system \"values in a row belong in a row\" is followed. Only the character that separates individual values can differ. A frequently used separator is the tab(ulator). The tab character is also often used in the `.smi` format. You will see this format more often when working with SMILES. If you are not sure which `seperator` is used, you can open the file with a simple text editor. On Windows, for example, \"Notepad\". Here you should see how the values are separated.\n",
    "\n",
    "In this case the data is stored in the format `.tab`. So the values are separated by a tab. You can use the function `pd.read_csv()` also if the file is not a `.csv` file. \n",
    "But then you must additionally specify the `separator` `sep=\"\\t\"`. The symbol `\"\\t\"` will then be recognized as a tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ab\")\n",
    "print(\"a\\tb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have already seen from some of the loaded libraries, today we will use some functions that are still unknown to you. \n",
    "\n",
    "- `pandas` contains useful functions for processing large amounts of data and can do pretty much everything Excel can do (and some things even better). `pandas` creates so called `DataFrames`. DataFrames are similar to 2D `arrays` in `numpy` and store data in rows and columns. The difference is that we can store different types of data in a `DataFrame`. For example `floats` and `strings` in two different columns. We can also assign names to the columns and rows to have a better overview of our data.\n",
    "\n",
    "- You already know `sklearn` from the ROC-AUC (Notebook 04).  `sklearn` brings many functions that are important for the preparation of data. There are also several machine learning algorithms in `sklearn`, including the Random Forest and Support Vector Machines.\n",
    "\n",
    "In the following cell, the data for a simple example is read in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example = pd.read_csv(\"https://uni-muenster.sciebo.de/s/Xxk3Q1zPIfjYMPz/download\", sep = \"\\t\")\n",
    "\n",
    "print(\"Type:\", type(toy_example))\n",
    "print(\"Shape:\",toy_example.shape)\n",
    "toy_example.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data read in with `pandas` is first stored in a `DataFrame`. This is a table with rows and columns. With `.head()` you can display the first 5 rows of a `DataFrame`. The data contains three columns: `x1` `x2` and `y`. In total the file contains 150 entries. So a total of 150 measuring points. \n",
    "\n",
    "`y` indicates the notional membership of each data point to one of two classes.\n",
    "\n",
    "To get a better overview, we create a diagram for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(toy_example.x1, toy_example.x2,\"o\")\n",
    "plt.plot( toy_example.x1[toy_example.y==1],  toy_example.x2[toy_example.y==1],\"o\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, one class is \"surrounds\" by the other. We want to train a SVM to distinguish the two classes.\n",
    "\n",
    "You should also notice that the scales of the two input variables `x1` and `x2` differ significantly. \n",
    " \n",
    "\n",
    "The `x1` values lie roughly in between `-1` and `1`. <br>The `x2` values lie between ca. `8` and `12`.\n",
    "\n",
    "We will not scale the data at first and directly train a SVM on this data. For this purpose the module `sklearn.svm` offers some functionalities. As with linear regression, `sklearn` first creates the model and then trains it.\n",
    "For classification, the function `SVC` (Support Vector Classification) can be used. First we create a variable `model`. This contains the Support Vector Classifier (`SVC`). To train it, we use the function `.fit(x,y)` to fit the classifier to our data. \n",
    "\n",
    "So far we have only trained the SVC, to get its predictions we need to use again the function `model.predict(x)`.\n",
    "\n",
    "\n",
    "**Important:** You may have seen it above, in `pandas` we can select variables (i.e. columns) directly from the `DataFrame`. So `toy_example.y` selects the column `y` from the DataFrame `toy_example`. \n",
    "If you want to select values using classical indexing, as with `arrays`, you must first append a `.iloc[]` to the DataFrame name. The indexing then works the same way as with `numpy`.\n",
    "\n",
    "`toy_example.iloc[:,:2]` selects the first two columns, i.e. `x1` and `x2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(toy_example.iloc[:,:2], toy_example.y)\n",
    "y_pred = model.predict(toy_example.iloc[:,:2])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the quality of the predictions, you can again use the accuracy. You can use the same function as in the last notebook. Calculate the accuracy for the predictions of this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true==y_pred)/len(y_true)\n",
    "\n",
    "accuracy(_____, ____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b></summary>\n",
    "\n",
    "```python\n",
    "accuracy(toy_example.y, y_pred)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is around `0.7`. Not bad, but there is still room for improvement. With one of the precoded functions in `utils.py` you can also make the decision boundaries visible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svc(toy_example, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the decision boundary is elongated. This is because the scale of `x2` is larger. This means that the distance from the decision boundary to the data points of two classes (which must be maximized) is easier to maximize for `x2` than for `x1`. Therefore, we see a good decision boundary for the values of `x2`, but not for `x1`. \n",
    "\n",
    "To change this, we can try to scale the data.\n",
    "To do this, we use what is called the `MinMax` scaler, where all values are scaled between `0` and `1`. We apply this scaler to both input variables (`x1`, `x2`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "toy_example.x1 = min_max(toy_example.x1)\n",
    "toy_example.x2 = min_max(toy_example.x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(toy_example.x1, toy_example.x2,\"o\")\n",
    "plt.plot( toy_example.x1[toy_example.y==1],  toy_example.x2[toy_example.y==1],\"o\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot looks exactly like the one before, but the scales, i.e. the x- and y-axis, have changed. \n",
    "That is, the relative relationship of the values has not changed.\n",
    "Can you now create a `model_2` with `SVC` that is trained with the scaled values? Also calculate the accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = ____\n",
    "model_2.fit(_____, ______)\n",
    "y_pred = model_2.predict(toy_example._____)\n",
    "accuracy(______,_____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b></summary>\n",
    "\n",
    "```python\n",
    "model_2 = SVC()\n",
    "model_2.fit(toy_example.iloc[:,:2], toy_example.y)\n",
    "y_pred = model_2.predict(toy_example.iloc[:,:2])\n",
    "accuracy(toy_example.y, y_pred)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaling of the input variables alone results in a 0.3 improvement in accuracy.\n",
    "A significant improvement can also be seen based in the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_svc(toy_example, model_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the data was generated just for this example, it shows why scaling the input variables is so important."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Splits\n",
    "\n",
    "\n",
    "From a theoretical example, we now move to a practical task: a toxicological prediction.\n",
    "`pandas` can automatically load data from websites and save them as a `dataframe`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/filipsPL/tox21_dataset/master/compounds/sr-mmp.tab\", sep = \"\\t\")\n",
    "\n",
    "print(\"Shape:\",data.shape)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains three columns: `Compound`, `SMILES` AND `activity`. In total the file contains 2246 molecules.\n",
    "\n",
    "- `Compound` contains the ID that can be used to distinguish the values in the original data set.\n",
    "- `SMILES` contains the SMILES-`strings`.\n",
    "- `activity` contains the results of the assay. A molecule is active (`1`) or inactive (`0`).\n",
    "\n",
    "---\n",
    "If you want to know how many active and therefore toxic molecules are contained in the data set, you can simply calculate the sum of the column `activity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(data.activity) # data.activity selects the column 'activity' contained in 'data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Compounds` column is not important for the analysis. Therefore we remove it from `data`. After that we rename the columns so that all names are lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:,1:] # all columns except the first one (index 0) are selected\n",
    "data.columns = [\"smiles\", \"activity\"]\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have data, but no input for your model. SMILES are `str` variables, but models need numeric variables as input. This means that you still have to create so called features. For this you can use the descriptors from the \"Cheminformatics\" notebook. In the following cells we convert the SMILES to `mol` and use them to calculate the descriptors. \n",
    "\n",
    "This time we also calculate the molar refractive index (measure of total polarizability), the number of rotatable bonds, and the TPSA (topological polar surface area). Then we combine all the variables into one `DataFrame`.\n",
    "\n",
    "Adjust the `for-loops`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert all SMILES to mols\n",
    "mols = np.array([Chem.MolFromSmiles(x) for x in ________ ]) # which SMILES have to be chosen\n",
    "\n",
    "# 1) N hydrogen bond donors\n",
    "num_hb_donors = [NumHDonors(x) for x in _______ ] # which variables do we loop over\n",
    "\n",
    "# 2) Hydrogen bond acceptors\n",
    "num_hb_acceptors = [NumHAcceptors(x) for _____ in ______] # which variables do we loop over\n",
    "\n",
    "# 3) Number of rotable bonds \n",
    "num_rotablebonds = [NumRotatableBonds(x) for x in mols]\n",
    "\n",
    "# 4) Molecular Mass: CalcExactMolWt()\n",
    "mw = [ _________(___ ) for x in mols]  # calculate the weight with CalcExactMolWt()\n",
    "\n",
    "# 5) log P: MolLogP()\n",
    "logP = [________ ___ __ __ ______] # calculate logP with MolLogP()\n",
    "\n",
    "# 6) Molar refractivity \n",
    "mr = [MolMR(x) for x in mols]\n",
    "\n",
    "# 7) Polar Surface\n",
    "tpsa = [CalcTPSA(x) for x in mols]\n",
    "\n",
    "aux_data=pd.DataFrame({\n",
    "    \"hb_donors\": num_hb_donors,\n",
    "    \"hb_acceptors\": num_hb_acceptors,\n",
    "    \"rotable_bonds\": num_rotablebonds,\n",
    "    \"mw\": mw,\n",
    "    \"logP\": logP,\n",
    "    \"mr\":mr,\n",
    "    \"tpsa\":tpsa\n",
    "    })\n",
    "\n",
    "aux_data[\"activity\"] = data.activity # we add the activity to the DataFrame\n",
    "aux_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b></summary>\n",
    "\n",
    "```python\n",
    "# convert all SMILES to mols\n",
    "mols = np.array([Chem.MolFromSmiles(x) for x in data.smiles])\n",
    "\n",
    "# 1) N hydrogen bond donors\n",
    "num_hb_donors = [NumHDonors(x) for x in mols]\n",
    "\n",
    "# 2) Hydrogen bond acceptors\n",
    "num_hb_acceptors = [NumHAcceptors(x) for x in mols]\n",
    "\n",
    "# 3) Number of rotable bonds \n",
    "num_rotablebonds = [NumRotatableBonds(x) for x in mols]\n",
    "\n",
    "# 4) Molecular Mass\n",
    "mw = [CalcExactMolWt(x) for x in mols]\n",
    "\n",
    "# 5) log P\n",
    "logP = [MolLogP(x) for x in mols]\n",
    "\n",
    "# 6) Molar refractivity \n",
    "mr = [MolMR(x) for x in mols]\n",
    "\n",
    "# 7) Polar Surface\n",
    "tpsa = [CalcTPSA(x) for x in mols]\n",
    "\n",
    "aux_data=pd.DataFrame({\n",
    "    \"hb_donors\": num_hb_donors,\n",
    "    \"hb_acceptors\": num_hb_acceptors,\n",
    "    \"rotable_bonds\": num_rotablebonds,\n",
    "    \"mw\": mw,\n",
    "    \"logP\": logP,\n",
    "    \"mr\":mr,\n",
    "    \"tpsa\":tpsa\n",
    "    })\n",
    "\n",
    "aux_data[\"activity\"] = data.activity \n",
    "aux_data\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame` `aux_data` has a separate column for each descriptor, seven in total. The first row contains the descriptors for the first molecule, the second for the second, and so on.\n",
    "You can now use this data set to build a model. \n",
    "However, there are some additional steps required before you can create a working model and make predictions.\n",
    "\n",
    "First, we have two types of variables. Variables like the number of rotatable bonds are called `discrete` because they contain only integers. There are no `3.5` rotatable bonds in a molecule. In contrast, variables such as logP or TPSA are \"continuous\", i.e., variables that can take values over the entire range of numbers.\n",
    "\n",
    "In addition, we have variables with different scales. Values for weight are much larger than values for logP or the number of HB acceptors, for example. \n",
    "\n",
    "However, since we want to use a Random Forests model next, the variables do not need to be scaled.\n",
    "This is because random forests do not use spacing or gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we divide the data set into 'x' and 'y', i.e. input und output\n",
    "x = aux_data.iloc[:,:7].values #'[:,:7]' => all columns except column 7\n",
    "y = aux_data.iloc[:,7].values #'[:,7]' => only column 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new variable `x` is now an `np.array` (instead of a `DataFrame`). This was made possible by the extension `.values`. So you can quickly convert `pd.DataFrame` to `np.arrays`. \n",
    "\n",
    "You can now train a random forest model. Similar to `SVC` you must first create a variable with the model and then use `.fit()` to train the model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42) \n",
    "# n_estimators sets the number of trees to use\n",
    "rf.fit(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how good the model is, we need to extract the prediciton of the model for our dater. Unlike usual, we use the function <br>`.predict_proba(x)[:,1]`. Using the trained `rf` model, we make the predictions for `y_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=rf.predict_proba(x)[:,1]\n",
    "y_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted probability for the first molecule is `0.014`. As with logistic regression, this means that according to our model the molecule is active in the MMP assay 1.4% of the time, i.e. it is unlikely to be toxic. The higher the probability, the more likely it is (according to the model) that the molecule is active in the assay. \n",
    "Often, 0.5 is chosen as the \"cut-off\" value. So, at a value of 0.5, we would expect the model to classify these molecules as toxic. \n",
    "\n",
    "To better assess how well the model is working, compare the predicted values `pred_y` with the actual values `y`.\n",
    "\n",
    "To do this, you can again take the Accuracy. To calculate the Accuracy, you first have to round the probabilities to `0` and `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_hat)\n",
    "accuracy(y, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can calculate the AUC with the function `roc_auc_score()`.\n",
    "Unlike `accuracy`, the probabilities `y_hat` are used here instead of the rounded values `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y, ____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b></summary>\n",
    "\n",
    "```python\n",
    "roc_auc_score(y,y_hat)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good. The model is almost perfect at prediction. It makes the correct decision in 99% of the cases. In the following cell, the misclassified molecules are selected and displayed with their predicted probability. It is not necessary that you understand this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "falsly_classified=np.where(y_pred!=y)[0]\n",
    "Draw.MolsToGridImage(mols[falsly_classified],\n",
    "                     legends=[\"Predicted Probability:\\n\"+str(np.round(x,3)) for x in y_hat[falsly_classified]],\n",
    "                     useSVG=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is notable that the probabilities for these molecules are mostly relatively close to 0.5. This means that the model was not very sure about these molecules. However, in total only 19 molecules were misclassified, so we should not worry too much.\n",
    "\n",
    "\n",
    "## Y-Scrambling\n",
    "\n",
    "##### The Problem:\n",
    "\n",
    "*Did the model really learn what is important for the MMP assay. Or did the RF model just memorize our data?*.\n",
    "\n",
    "We can find this out with a simple test. We train the RF model again, but shuffle the variable `activity` randomly. That is, the true measurements are shuffled and redistributed, randomly, among the molecules. This process is also called **Y-scrambling**. \n",
    "\n",
    "Suppose our real data looks like this:\n",
    "\n",
    "smiles|Deskriptor 1| Deskriptor 2|activity\n",
    "------|------------|-------------|--------\n",
    "SMILES 1|$x_{1,1}$ |$x_{1,2}$|$y_1$\n",
    "SMILES 2|$x_{2,1}$ |$x_{2,2}$|$y_2$\n",
    "SMILES 3|$x_{3,1}$ |$x_{3,2}$|$y_3$\n",
    "SMILES 4|$x_{4,1}$ |$x_{4,2}$|$y_4$\n",
    "\n",
    "Two descriptors were calculated for each SMILES. We also recorded the activity ($y_1$-$y_4$) for each molecule. The activity $y_1$ is the measured activity of SMILES 1 and so on.\n",
    "\n",
    "After *Y-scrambling*, our data looks like this:\n",
    "\n",
    "smiles|Deskriptor 1| Deskriptor 2|activity\n",
    "------|------------|-------------|--------\n",
    "SMILES 1|$x_{1,1}$ |$x_{1,2}$|$y_2$\n",
    "SMILES 2|$x_{2,1}$ |$x_{2,2}$|$y_3$\n",
    "SMILES 3|$x_{3,1}$ |$x_{3,2}$|$y_4$\n",
    "SMILES 4|$x_{4,1}$ |$x_{4,2}$|$y_1$\n",
    "\n",
    "The $y$ values were randomly assigned to other molecules."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Y-scrambling leads to the loss of the actual relationship, between the variables `x` (i.e. our descriptors like logP,...) and the variable `y` to be predicted.  This is because the relationship is now just random. If our random forest actually learns patterns instead of memorizing the data, then the model should perform worse on this data set.\n",
    "\n",
    "To try this out, you will need the `random` library. The function `random.shuffle()` randomly reorders the values of `y`. You can then re-train the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(15) # a seed ensures that you all get the same random data\n",
    "y_random=np.array(y) # first we store y in an array\n",
    "random.shuffle(y_random) # then we shuffle y_random, we don't need to store this variable extra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just reshuffled the activity information. Now we can train a random forest model. However, this time we do not use `y`, but `y_random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain the model \n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(x, ______) # Which y variable do you need?\n",
    "y_hat=rf.predict_proba(x)[:,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b></summary>\n",
    "\n",
    "```python\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(x, y_random) \n",
    "y_hat=rf.predict_proba(x)[:,1]\n",
    "```\n",
    "</details>\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the Accuracy again (make sure that we use `y_random` again and not `y` for `y_true`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_hat)\n",
    "accuracy(y_random, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the accuracy deteriorates after Y-scrambling. But the accuracy is still above 90%. The random forest model is still relatively good at predicting toxicity, even though the data you used no longer makes any sense at all. The model could not have learned at all, since there is no relationship between `x` and `y`. Thus, the RF model has achieved its accuracy only by memorizing the data. \n",
    "\n",
    "For this reason, a test data set is always used. This test data set is not used during training, and so the model sees these molecules for the first time when we want to evaluate the quality of the model. Memorizing the molecules in the training data set can still happen, but it does not help the model with the molecules we have in the test data set.  \n",
    "\n",
    "---\n",
    "Often datasets are split not only into training/test sets, but into training/validation/test sets.\n",
    "The models are then optimized based on the validation set and only the optimized model is then tested on the test set.\n",
    "In cheminformatics, the validation set is sometimes referred to as the test set. The actual test set is then referred to as the external validation set.\n",
    "\n",
    "---\n",
    "Here, too, there are functions that do the work for you. The function `train_test_split` splits the data into a test set and a training set. We use 80% of the data set for training and the rest for validation. The molecules are then randomly divided between the two sets. Then the data is again split into `x` and `y`, but this time for `train` and `test` separately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test=train_test_split(aux_data,test_size= 0.2, train_size= 0.8, random_state=1234)\n",
    "\n",
    "train_x = train.iloc[:,:7]\n",
    "train_y = train.iloc[:,7]\n",
    "test_x = test.iloc[:,:7]\n",
    "test_y =  test.iloc[:,7]\n",
    "f\"Train Shape: {train.shape}, Test Shape: {test.shape}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainings set contains 1796 molecules and the test set 450. \n",
    "\n",
    "We first train the Random Forest with the training data only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(train_x, train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we only make the predictions for the molecules in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=rf.predict_proba(test_x)[:,1]\n",
    "y_pred = np.round(y_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now also calculate the accuracy. Which variable do we need now for `y_true`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(___, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b></summary>\n",
    "\n",
    "```python\n",
    "accuracy(test_y, y_pred)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy has deteriorated by quite a bit, but it is still good. This time, however, we can be sure that the performance is not due to memorization, since the model has never seen these molecules. If we now apply Y-scrambling, the performance should deteriorate dramatically. \n",
    "We replace the `aux_data.activity` with the previously created `y_random`. These are the mixed `y` values and we repeat the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_data.activity = y_random "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we divide the data again into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_random, test_random=train_test_split(aux_data,test_size= 0.2, train_size= 0.8, random_state=1234)\n",
    "train_x_random = train_random.iloc[:,:7]\n",
    "train_y_random = train_random.iloc[:,7]\n",
    "test_x_random = test_random.iloc[:,:7]\n",
    "test_y_random =  test_random.iloc[:,7]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the training with the randomized data. Then we let the model make predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(train_x_random, train_y_random)\n",
    "y_hat=rf.predict_proba(test_x_random)[:,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_hat)\n",
    "accuracy(test_y_random, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a test set, the accuracy of the model with the Y-scrambled data drops dramatically to about 50%. It is no better than a model that would simply guess.\n",
    "Only by using a test set could we show that the model learned something beyond memorization\n",
    "The main point was to show the importance of evaluating a model not only based on the training set. \n",
    "\n",
    "Y-scrambling is rarely used in practice. But the OECD, for example, requires a Y-scrambling test to validate QSAR (Quantitative Structure-Activity Relationship) models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "As a final step, let's look at the **Feature Importance**. The feature importance indicates how important each input variable is to the decision. Depending on which ML algorithm you use, you can extract the feature importance relatively easily. We first re-train our RF, this time with a data split.\n",
    "\n",
    "In the next cell, we first re-train the random forest model (without y-scrambling). Then we can output the feature importance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_data.activity = data.activity\n",
    "\n",
    "train, test=train_test_split(aux_data,test_size= 0.2, train_size= 0.8, random_state=1234)\n",
    "train_x = train.iloc[:,:7]\n",
    "train_y = train.iloc[:,7]\n",
    "test_x = test.iloc[:,:7]\n",
    "test_y =  test.iloc[:,7]\n",
    "\n",
    "\n",
    "# train model\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(train_x, train_y)\n",
    "y_hat=rf.predict_proba(test_x)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(rf.feature_importances_, index=aux_data.columns.values[:-1])\n",
    "feat_importances.nlargest(20).nsmallest(20).plot(kind='barh')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clearly evident that the LogP is the most important parameter for determining toxicity, while the number of H-bridge donors and acceptors are less relevant. \n",
    "\n",
    "That the LogP value is important is not surprising. For example, we can look at the density plots of active and inactive molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(aux_data.logP[aux_data.activity==1], color=\"red\")\n",
    "sns.kdeplot(aux_data.logP[aux_data.activity==0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a clear trend. At higher LogP, the molecule is more active. \n",
    "\n",
    "Try it yourself with the other descriptors(`hb_donors`, `hb_acceptors`, `rotable_bonds`, `mw`, `mr`, `tpsa`). Besides LogP, which descriptors have different distribution based on activity?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Exercise \n",
    "\n",
    "You have already learned about fingerprints as molecular representations. Since they are easy to calculate and always have a fixed length, they are well suited as input for ML models. However, fingerprints are not so easy for humans to interpret.\n",
    "\n",
    "Your task will be to train a Random Forest model again. This time you will use the ECFP4 as input.\n",
    "\n",
    "For you, the function `get_fingerprints()` has already been precoded. With it you can compute fingerprints from the SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fps = get_fingerprints(data)\n",
    "fps[\"activity\"] = data.activity\n",
    "fps.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fps` contains a total of 2049 columns. 2048 of them are the respective bits of the fingerprint. The last column contains the `activity`.\n",
    "\n",
    "First, the data set is divided into `training` and `test`. 80% of the data should be in the training set and 20% in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(_____,test_size= ___ , train_size= ______, random_state=1234)\n",
    "\n",
    "train_x = __________\n",
    "train_y = __________\n",
    "test_x = __________\n",
    "test_y = __________ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the data, train a random forest classifier with the training dataset.\n",
    "Then use the trained model to classify the molecules in the `test` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(_____, _____)\n",
    "y_hat=rf.predict_proba(______)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(___,____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take another look at the feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(rf.feature_importances_, index=range(2048))\n",
    "feat_importances.nlargest(20).nsmallest(20).plot(kind='barh', title = \"Importance of Features\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this plot can no longer be interpreted as easy, even though it becomes clear that the top five bits are important for the activity prediction.\n",
    "\n",
    "The bits can't be plotted that well, but with RDKit we can show the substructures that are assigned to each bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "most_important_bits = feat_importances.nlargest(20).index.values\n",
    "print(\"The 20 most important bits:\", most_important_bits)\n",
    "mol_ll = []\n",
    "bi_ll = []\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    bit = most_important_bits[i]\n",
    "    for x in data.smiles:\n",
    "        bi ={}\n",
    "        mol = Chem.MolFromSmiles(x)\n",
    "        fp = Chem.rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius=2, bitInfo=bi)\n",
    "        if np.sum(np.array(list(bi))==bit)>0:\n",
    "            mol_ll.append(mol)\n",
    "            bi_ll.append(bi)\n",
    "            break\n",
    "        \n",
    "prints=[(mol_ll[i],most_important_bits[i], bi_ll[i]) for i in range(20)]\n",
    "\n",
    "Draw.DrawMorganBits(prints, useSVG=True, molsPerRow=3, legends= [str(most_important_bits[i]) for i in range(20)], subImgSize= [300,300])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important bit for our data is a phenolic hydroxy group (aromatic atoms are highlighted in yellow, the central atom is blue). Many other aromatic fragments are also represented in the most important bits."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2063f454e5583264956edca724ed174a35400d49c5baf96fcf9ea99fcd5830b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
