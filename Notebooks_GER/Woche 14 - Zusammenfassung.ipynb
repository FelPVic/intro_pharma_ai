{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6c2e50",
   "metadata": {},
   "source": [
    "# Ein Überblick\n",
    "\n",
    "---\n",
    "Lernziel\n",
    "\n",
    "- Sie verstehen den Zusammenhang einer (logistischer) Regression und Neuronalen Netzwerken.\n",
    "---\n",
    "\n",
    "Im letzten Notebook werden wir uns noch ein letztes Mal mit verschieden Netzwerk-Architekturen auseinandersetzen und wie diese zusammen hängen.\n",
    "\n",
    "Dafür werden wir noch einmal mit dem MNIST Datensatz arbeiten. Zunächst laden wir wieder die Daten und normalisieren diese. Wir kodieren die Target Variable auch wieder zu One-Hot Vektoren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ace8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "def min_max(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "def one_hot(x):\n",
    "    \"\"\"Die Labels der Bilder müssen noch in Vektoren von Länge 10 codiert werden\"\"\"\n",
    "    dod = len(set(x)) # Checkt wie viele verschieden Ziffern es im Datennsatz gibt\n",
    "    target = np.zeros([x.shape[0], dod]) # Eine Matrix aus Nullen wird erstellt\n",
    "    for i in range(x.shape[0]): # Der for-loop setzt eine 1 in die Matrix abhängig davon welches Label das Bild hat\n",
    "        target[i, x[i]] = 1\n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81def756",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt('https://uni-muenster.sciebo.de/s/vVaMBQUQf5evomw/download', delimiter=',', skip_header =False) #genfromtxt liest .txt Datein, mit delimiter =\",\" können auch .csv (comma seperated values) Datein einglesen werden  \n",
    "test_data = np.genfromtxt('https://uni-muenster.sciebo.de/s/1l80v7o5iLPgDEX/download', delimiter=',', skip_header =False) # hier lesen wir die Test Daten ein\n",
    " \n",
    "train_labels=train_data[:,0].astype(int) \n",
    "train_images = train_data[:,1:]\n",
    "\n",
    "test_labels=test_data[:,0].astype(int)\n",
    "test_images = test_data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets=one_hot(train_labels)\n",
    "test_targets = one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = min_max(train_images)\n",
    "test_images = min_max(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc937fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0].reshape([28, 28]), cmap=\"gray\")\n",
    "print(\"Correct Label: %s\" % train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e54a43",
   "metadata": {},
   "source": [
    "# Lineare Regression\n",
    "\n",
    "Wir beginnen mit einer einfachen Regression. Eine lineare Regression kann auch als neuronales Netz dargestellt werden.\n",
    "\n",
    "<img src=\"Img/summary/lin_reg.png\" width =\"450px\">\n",
    "\n",
    "Die Ausgabe setzt sich aus der gewichteten Summe der Pixelwerte zusammen. Das heißt, jedem Pixel wird ein Gewicht zugewiesen. *Das Neuron kann auch noch eine Bias haben, aber das wird nicht gezeigt*. \n",
    "\n",
    "Da wir nur ein Ausgangsneuron haben, können wir auch nur eine Vorhersage treffen. Das bedeutet, dass wir nur eine binäre Klassifizierung durchführen können. Zum Beispiel: Ist auf dem Bild eine Fünf zu sehen? JA oder NEIN.\n",
    "\n",
    "Wir können diese lineare Regression auch in Python durchführen.\n",
    "Dazu verwenden wir die `train_images` als Eingabe und die Spalte von `train_targets`. In diesem Fall ist es die fünfte Spalte `train_targets[:,5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97faed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear_reg_model = LinearRegression()\n",
    "linear_reg_model.fit(train_images, train_targets[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd898602",
   "metadata": {},
   "source": [
    "Wir können die Gewichte mit `linear_reg_model.coef_` ausgeben. Es gibt insgesamt 784 Gewichte, eines für jedes Pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed115ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear_reg_model.coef_[:5], linear_reg_model.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a832de9",
   "metadata": {},
   "source": [
    "Um zu sehen, wie gut unser Modell funktioniert, können wir die Funktion `.predict()` verwenden, um den Wert für unseren Testdatensatz vorherzusagen. Denken Sie daran, dass wir nur Nullen oder Einsen vorhersagen wollen.\n",
    "\n",
    "`1` = \"Fünf\"\n",
    "\n",
    "`0` = \"Keine Fünf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = linear_reg_model.predict(test_images)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851eb70",
   "metadata": {},
   "source": [
    "Diese Werte sind weder `0` noch `1`. Wir müssen diese erst noch runden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b62c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_y = np.round(pred_y)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2aab8",
   "metadata": {},
   "source": [
    "Jetzt können wir auch die Accuracy berrechen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_y== test_targets[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d6b9d",
   "metadata": {},
   "source": [
    "`0,9456` ist nicht so schlecht. Aber bedenken Sie, dass nur etwa 10 % der Bilder eine `5` zeigen. Das bedeutet auch, dass 90% der Bilder keine `5` zeigen. Für diese 90 % müsste unser Modell eine  `0` vorhersagen, um richtig zu sein. Wenn das Modell einfach eine `0` für alle Bilder vorhersagt, hätte es eine Accuarcy von `0,90`. Unsere Accuracy ist also vielleicht weniger gut als ursprünglich angenommen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe7450",
   "metadata": {},
   "source": [
    "Wir haben noch ein weiteres Problem. Schauen Sie sich einmal die Vorhersagen für `pred_y[1677]` oder `pred_y[1162]` an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ae3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y[1677],pred_y[1162]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340240b",
   "metadata": {},
   "source": [
    "Diese Werte sind weder `1` noch `0`. Wie konnte das passieren?\n",
    "Bei einer linearen Regression verwenden wir keine Aktivierungsfunktionen. Daher kann die Ausgabe einer linearen Regression unbegrenzt große oder kleien Werte annehmen. Wenn die Werte außerhalb von `[-1.5, 1.5]` liegen, werden sie nicht auf `0` oder `1` gerundet.\n",
    "\n",
    "Das ist zunächst kein Problem, wir könnten diesen Werten auch manuell `0` oder `1` zuweisen. Aber das Problem bleibt im Prinzip bestehen: Wie erlauben dem Modell Werte vorherzusagen, die außerhalb des möglichen Bereichs liegen. \n",
    "\n",
    "Eine `sigmoid`-Funktion verhindert dies. Sie transformiert alle Werte so, dass sie immer zwischen `0` und `1` liegen. Wir können also einfach eine `sigmoid`-Funktion an die lineare Regression \"hängen\". Damit wäre das Problem gelöst. Und genau das passiert bei der logistischen Regression.\n",
    "\n",
    "<img src=\"Img/summary/log_reg.png\" width=\"450px\">\n",
    "\n",
    "Wir können dies auch in Python berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(solver = 'lbfgs', max_iter=1000,  random_state=134)\n",
    "log_reg_model.fit(train_images, train_targets[:,5])\n",
    "log_reg_model.coef_[0,256:261], log_reg_model.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbceea4",
   "metadata": {},
   "source": [
    "Wir erhalten wieder `784` Weights. Für jeden Pixel eins. Wir sehen auch, dass unsere Vorhersagen für den Testdatensatz jetzt schon gerundet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = log_reg_model.predict(test_images)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85190e3d",
   "metadata": {},
   "source": [
    "Auch hier berechnen wir wieder die Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07aa814",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_y == test_targets[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328659d",
   "metadata": {},
   "source": [
    "Mit Hilfe der logistischen Regression könnten wir also die Genauigkeit erhöhen. Bisher unterscheiden wir aber nur zwischen \"Fünf\" und \"Keine Fünf\". Wir wollen aber eigentlich jede Ziffer erkennen können. Auch das ist mit logistischer Regression möglich.\n",
    "\n",
    "Das heißt, wir haben mehrere Outputnodes. Insgesamt 10, für jede Ziffer eine. \n",
    "\n",
    "<img src=\"Img/summary/log_reg_2.png\" width=\"540px\">\n",
    "\n",
    "Die Funktion `softmax` wird nun verwendet. Im Gegensatz zur `sigmoid`-Funktion stellt die `softmax`-Funktion sicher, dass die Summe der Aktivierungen über die 10 Outputs immer genau `1` ist. Würden wir die `sigmoid` Funktion verwenden, könnte es passieren, dass ein Bild als eine Fünf und eine Eins erkannt wird. \n",
    "\n",
    "\n",
    "Für diese logistische Regression müssen wir nun die kompletten `train_labels` Matrix hinzufügen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model_alle = LogisticRegression(solver = 'lbfgs', max_iter=1000,  random_state=134)\n",
    "log_reg_model_alle.fit(train_images, train_labels)\n",
    "log_reg_model_alle.coef_[0,256:261], log_reg_model_alle.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7152f511",
   "metadata": {},
   "source": [
    "Die Weightmatrix `log_reg_model_alle.coef_` hat nun die Größe `[10,784]`. Also pro Outputneuron 784 Weights.\n",
    "\n",
    "Auch jetzt erhalten wir Vorhersagen, diesen enthält die vom Model erkannte Zahl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432398e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_y = log_reg_model_alle.predict(test_images)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15d07b",
   "metadata": {},
   "source": [
    "Wir berechnen erneut die Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ce0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_y==test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c600a",
   "metadata": {},
   "source": [
    "Das Modell kann 92,5 % der Ziffern richtig erkennen. Das ist natürlich schlechter als vorher, aber diesmal ist die Aufgabe viel komplexer, denn es geht nicht nur um eine Ziffer, sondern es müssen alle Zahlen richtig erkannt werden. \n",
    "Mit einer einfachen logistischen Regression können wir also eine relativ gute Accuracy erreichen. \n",
    "\n",
    "Wozu brauchen wir dann neuronale Netze? Diese können uns auch die letzten Prozentpunkte an Leistung bringen. Der Unterschied zwischen unserem aktuellen Modell und einem neuronalen Netz ist das Fehlen von Hidden Layers. \n",
    "\n",
    "<img src=\"Img/summary/nn1.png\" width=\"450px\">\n",
    "\n",
    "Wir werden dies auch mit PyTorch nachbauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cd1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images =torch.tensor(train_images, dtype = torch.float32)\n",
    "test_images =torch.tensor(test_images, dtype = torch.float32)\n",
    "\n",
    "train_labels =torch.tensor(train_labels, dtype = torch.long)\n",
    "test_labels =torch.tensor(test_labels, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn = nn.Sequential(nn.Linear(784,10),nn.ReLU() ,nn.Linear(10,10))\n",
    "loss_funktion = nn.CrossEntropyLoss()\n",
    "updater = optim.Adam(simple_nn.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "for epoch in range(135):\n",
    "    updater.zero_grad()\n",
    "    output = simple_nn(train_images)\n",
    "    loss = loss_funktion(output, train_labels)\n",
    "    loss.backward()\n",
    "    updater.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae5cfb",
   "metadata": {},
   "source": [
    "Der Code sollte Ihnen inzwischen vertraut sein. Wenn wir uns jedoch die Genauigkeit ansehen, sehen wir, dass das neuronale Netz eine Accuracy hat, die mit der Accuracy der logistischen Regression vergleichbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y=torch.argmax(simple_nn(test_images),1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_y==test_labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48b226",
   "metadata": {},
   "source": [
    "Dies kann mehrere Gründe haben. Im Prinzip müssen neuronale Netze nicht besser funktionieren als einfachere Modelle.\n",
    "In diesem Fall liegt es aber wahrscheinlich an unserem Modell selbst. Wir können mehr oder größere Layers verwenden. Oder wir ändern den Optimizer oder die Lernrate.\n",
    "\n",
    "\n",
    "\n",
    "# Übungsaufgabe\n",
    "\n",
    "\n",
    "Das heutige Notebook ist kürzer als sonst, so dass Sie mehr Zeit für die Übung haben. \n",
    "In der heutigen Übungsaufgabe geht es darum, das Gelernte noch einmal auf den MNIST-Datensatz anzuwenden. \n",
    "\n",
    "Sie erhalten drei Datensätze (zufällig gemischt):\n",
    "\n",
    "- Trainingsdaten: verwenden Sie zum Trainieren\n",
    "- Testdaten: zur Bewertung des trainierten Netzwerks\n",
    "- Externer Testdatensatz: nur Bilder, keine Beschriftung → Sie schicken mir die Vorhersagen für diesen Datensatz.\n",
    "\n",
    "Der externe Datensatz hat keine Lösungen (zumindest keine, die Sie einsehen können). \n",
    "Bei der Übungsaufgabe geben Sie auch **ihre** Vorhersagen für den externen Datensatz ab.\n",
    "\n",
    "Wir werden dann Ihre Vorhersagen mit den wahren Werten vergleichen. \n",
    "*Wer von Ihnen erstellt das beste Modell?*\n",
    "\n",
    "Es wurde ein erstes Modell vorgegeben.\n",
    "Von dort aus können Sie Ihr Netzwerk verbessern.\n",
    "\n",
    "Es gibt mehrere Möglichkeiten, Ihr Netzwerk zu verbessern:\n",
    "Hier sind ein paar Beispiele.\n",
    "\n",
    "- Anpassung von Hyperparametern, z. B. Anzahl der Epochen, Stapelgröße, Lernrate oder Anzahl der versteckten Schichten\n",
    "- Batchnorm und Dropout\n",
    "- CNN\n",
    "- Optimierer\n",
    "\n",
    "Achten Sie darauf, dass Sie den Testdatensatz nicht zu stark anpassen. Auch das kann passieren.\n",
    "\n",
    "Am Ende des Codes befindet sich eine Zelle, mit der Sie die Vorhersage für den Testdatensatz erstellen und speichern können. \n",
    "Diese wird im Ordner `data` als `my_prediction.csv` gespeichert.\n",
    "\n",
    "Bitte reichen Sie sowohl Ihre Vorhersage als auch das Notebook ein.\n",
    "\n",
    "\n",
    "# Daten \n",
    "\n",
    "Laden Sie zunächst alle Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "\n",
    "def min_max(x):\n",
    "    return (x - 0.) / (255. - 0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cecd01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt('https://uni-muenster.sciebo.de/s/vVaMBQUQf5evomw/download', delimiter=',', skip_header =False)\n",
    "train_labels=train_data[:,0].astype(int) \n",
    "train_images = min_max(train_data[:,1:])\n",
    "del train_data \n",
    "\n",
    "test_data = np.genfromtxt('https://uni-muenster.sciebo.de/s/1l80v7o5iLPgDEX/download', delimiter=',', skip_header =False)\n",
    "test_labels=test_data[:,0].astype(int)\n",
    "test_images = min_max(test_data[:,1:])\n",
    "del test_data \n",
    "\n",
    "external_images=min_max(np.genfromtxt('https://uni-muenster.sciebo.de/s/0kAd13OWqx1FPZD/download', delimiter=',', skip_header =False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images =torch.tensor(train_images, dtype = torch.float32)\n",
    "test_images =torch.tensor(test_images, dtype = torch.float32)\n",
    "\n",
    "train_labels = torch.tensor(train_labels, dtype = torch.long)\n",
    "test_labels = torch.tensor(test_labels, dtype = torch.long)\n",
    "\n",
    "external_images = torch.tensor(external_images, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.TensorDataset(train_images, train_labels) # input sind unsere Tensors die einmal die Bilder und einmal die Labels beinhalten\n",
    "loader = data.DataLoader(train_data, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0c6e8",
   "metadata": {},
   "source": [
    "##  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn = nn.Sequential(nn.Linear(784,10),nn.ReLU() ,nn.Linear(10,10))\n",
    "loss_funktion = nn.CrossEntropyLoss()\n",
    "updater = optim.Adam(simple_nn.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffd5fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "for epoch in range(20):\n",
    "    simple_nn.train()\n",
    "    for images, labels in loader:\n",
    "        updater.zero_grad()\n",
    "        output = simple_nn(images)\n",
    "        loss = loss_funktion(output, labels)\n",
    "        loss.backward()\n",
    "        updater.step()\n",
    "    \n",
    "    simple_nn.eval()\n",
    "    # EVALUATE #\n",
    "    # Train\n",
    "    output = simple_nn(train_images)\n",
    "    loss = loss_funktion(output, train_labels)\n",
    "    prediction = torch.argmax(output,1).detach().numpy()\n",
    "    acc  = np.mean(prediction == train_labels.detach().numpy()  )\n",
    "    # Tets\n",
    "    output = simple_nn(test_images)\n",
    "    test_loss = loss_funktion(output, test_labels)\n",
    "    prediction = torch.argmax(output,1).detach().numpy()\n",
    "    test_acc  = np.mean(prediction == test_labels.detach().numpy()  )\n",
    "    print(f\"Epoch {epoch} | Trainings Loss: {loss:.3f} Training Acc: {acc:.3f} | Test Loss: {test_loss:.3f} Test Acc:  {test_acc:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3baff30",
   "metadata": {},
   "source": [
    "# Externe Daten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d391273",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn.eval()\n",
    "externe_pred = torch.argmax(simple_nn(external_images),1).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8261ba",
   "metadata": {},
   "source": [
    "Die nächste Zelle generiert eine `.csv` Datein mit Ihren Vorhersagen. Diese reichen Sie bitte mit dem Notebook ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(externe_pred.reshape(10000,1)).to_csv(\"../data/meine_prediction.csv\", index =False,header =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
