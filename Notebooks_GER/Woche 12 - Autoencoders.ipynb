{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978f8a26",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "#### Ich habe mein Bestes getan, um die Trainingszeit zu minimieren. Ich hatte ein bereits trainiertes Modell gespeichert. Allerdings spielt der Server nicht mit. Deswegen am besten beim Training einfach eine Stunde lang etwas anderes machen. Man muss nicht 100 Epochen trainieren, sondern kann das Training über Kernel > Interrupt Kernel vorzeitig beenden.\n",
    "---\n",
    "**Lernziele**\n",
    "- Sie verstehen das Konzept eines Autoencoders.\n",
    "- Sie verstehen, wie ein RNN SMILES erzeugen kann.\n",
    "- Sie können ein Netzwerk auch als PyTorch-Class definieren.\n",
    "- Sie verstehen die Bedeutung der `<sos>`/`<eos>`-Tokens.\n",
    "---\n",
    "\n",
    "Im heutigen Notebook beschäftigen wir uns mit den sogenannten **Autoencodern**.\n",
    "Autoencoder werden meist durch selfsupervised Training trainiert.\n",
    "Zur Erinnerung: selfsupervised Training bezieht sich auf das Training von neuronalen Netzen, bei denen Input und Output identisch sind. Das Ziel besteht also darin, die Input wiederherzustellen. \n",
    "\n",
    "Aber was ist der Mehrwert eines Netzes, das nur den Input wiederherstellt?\n",
    "In der Tat sind wir nicht unbedingt an dem Output eines Autoencoders interessiert. Uns interessiert vielmehr, was in der Mitte des Netzes passiert. \n",
    "Das liegt daran, dass das eigentliche Ziel von Autoencodern darin besteht, die Daten zu komprimieren, d. h. sie so effektiv wie möglich darzustellen.\n",
    "\n",
    "Das Beispielbild zeigt einen Autoencoder für Bilder:\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/b1786e74e233ac21f503f59d03f6af19a3699024/2-Figure1-1.png\" >\n",
    "\n",
    "*Yifei Zhang - A Better Autoencoder for Image: Convolutional Autoencoder * **2018**\n",
    "\n",
    "\n",
    "Ein Autoencoder besteht aus zwei Netzwerken, einem **Encoder** und einem **Decoder**. Die Output des Encoders wird als Input für den Decoder verwendet. Der Encoder soll lernen, die Daten so effektiv wie möglich in einem niedrigdimensionalen Raum (latenter Space) zu repräsentieren. Diese Darstellung ist in der Regel einfach ein Vektor, der auch als **latenter Vektor** bezeichnet wird. Der Decoder wird darauf trainiert, den ursprünglichen Input anhand dieses latenten Vektors wiederherzustellen. \n",
    "\n",
    "Wir können selbst bestimmen, wie groß der latente Vektor sein soll. Meistens wird eine besonders kleine Größe gewählt, um eine größere Kompression zu gewährleisten.\n",
    "Nach erfolgreichem Training sollte der *latente Vektor* trotz seiner geringen Größe genügend Informationen enthalten, um das Bild wieder vollständig auszugeben. Das bedeutet, dass dieser Vektor ausreichend informativ ist, um das komplette Bild zu beschreiben. Tatsächliche Anwendungen gehen über die einfache Rekonstruktion hinaus.\n",
    "\n",
    "Zum Beispiel werden Autoencoder eingesetzt, um die Qualität von Bildern zu verbessern. Dazu werden niedrig aufgelöste Bilder als Input verwendet, und der Output ist das gleiche Bild in seiner regulären (höheren) Auflösung. Auf diese Weise werden Netzwerke trainiert, die später niedrig aufgelöste Bilder schärfen können. \n",
    "\n",
    "\n",
    "<img src=\"https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/60bcd0b7b750bae1a953d61d_autoencoder.png\" width =\"400px\">\n",
    "\n",
    "*Hmrishav Bandyopadhyay - An Introduction to Autoencoders: Everything You Need to Know* **2021**\n",
    "\n",
    "Autoencoder gibt es nicht nur für Bilder, sondern auch für Text. RNNs werden für diesen Zweck verwendet. \n",
    "Im letzten Notebooks haben wir bereits besprochen, dass der letzte Hidden State eines RNNs eine Zusammenfassung der gesamten Inputsequenz ist. Im Beispiel der Hidden State $O_5$\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/724/1*1U8H9EZiDqfylJU7Im23Ag.gif\">\n",
    "\n",
    "*Michael Phi - An illustrated Guide to Recurrent Neural Networks*\n",
    "\n",
    "\n",
    "Der Output $O_5$ kann bereits als eine Projektion des gesamten Satz in den laten Space verstanden werden. Der Hidden State $O5$ ist also der latente Vektor, der unsere Sequenz beschreibt. Dementsprechend ist das Netzwerk, das diesen Vektor erzeugt hat, auch unser Encoder. Für unseren Autoencoder fehlt also nur noch der Decoder, der aus dem latenten Vektor den ursprünglichen Satz wiederherstellen kann. Wie das genau funktioniert, werden wir anhand eines Beispiels mit Smiles diskutieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sys\n",
    "from os.path import exists, isdir\n",
    "import os \n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install rdkit==2022.3.4\n",
    "    if exists(\"utils.py\") == False:\n",
    "        !wget https://raw.githubusercontent.com/kochgroup/intro_pharma_ai/main/utils/utils.py\n",
    "    if exists(\"load_fragments.ipynb\") == False:\n",
    "        !wget https://raw.githubusercontent.com/kochgroup/intro_pharma_ai/main/utils/load_fragments.ipynb\n",
    "    %run utils.py\n",
    "    %run load_fragments.ipynb\n",
    "else:\n",
    "    %run ../utils/utils.py\n",
    "    %run ../utils/load_fragments.ipynb\n",
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit import RDLogger \n",
    "RDLogger.DisableLog('rdApp.*')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2d9e1",
   "metadata": {},
   "source": [
    "Diese Woche benutzen wir einen Datensatz der sich aus einem kleinen Teil der, von der Reymond Gruppe entwickelten, GDB 11 besteht. Nur besonders kleine Moleküle werden hier verwedent. Für uns ist das besonders wichtig, da die Moleküle nicht zu groß werden dürfen. Es ist grundsätzlich schwierig, aus einem latenten Vektor einen gültigen Smiles String zu erzeugen. Je länger die Smiles Strings werden, desto komplexer wird die Aufgabe für das Netzwerk.\n",
    "\n",
    "Diese Woche liegen die Moleküle auch in einem anderen Dateiformat vor. Im Format `.sdf` werden die Moleküle mit mehr Details gespeichert. Zum Beispiel können hier auch Informationen über die Konformation gespeichert werden. \n",
    "\n",
    "---\n",
    "Fink, T., & Reymond, J. L.. Virtual exploration of the chemical universe up to 11 atoms of C, N, O, F: assembly of 26.4 million structures (110.9 million stereoisomers) and analysis for new ring systems, stereochemistry, physicochemical properties, compound classes, and drug discovery. J. Chem. Inf. Model. **2007** 47(2), 342-353.\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "\n",
    "  Mrv0541 07182119162D          \n",
    "\n",
    " 12 12  0  0  0  0            999 V2000\n",
    "    0.7145    2.0625    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.7145    1.2375    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    1.4289    0.8250    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    1.4289   -0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    2.1434   -0.4125    0.0000 F   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.7145   -0.4125    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.7145   -1.2375    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    1.4289   -1.6500    0.0000 O   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   -0.0000   -1.6500    0.0000 O   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.0000    0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   -0.7145   -0.4125    0.0000 F   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.0000    0.8250    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "  1  2  1  0  0  0  0\n",
    "  2  3  4  0  0  0  0\n",
    "  3  4  4  0  0  0  0\n",
    "  4  5  1  0  0  0  0\n",
    "  4  6  4  0  0  0  0\n",
    "  6  7  1  0  0  0  0\n",
    "  7  8  2  0  0  0  0\n",
    "  7  9  1  0  0  0  0\n",
    "  6 10  4  0  0  0  0\n",
    " 10 11  1  0  0  0  0\n",
    " 10 12  4  0  0  0  0\n",
    "  2 12  4  0  0  0  0\n",
    "M  END\n",
    ">  <Catalog ID>\n",
    "Z1255462241\n",
    "\n",
    ">  <PlateID>\n",
    "1225133-R3-01\n",
    "\n",
    ">  <Well>\n",
    "A02\n",
    "\n",
    ">  <MW (desalted)>\n",
    "172.129\n",
    "\n",
    ">  <CLogP>\n",
    "2.082\n",
    "\n",
    ">  <HBD>\n",
    "1\n",
    "\n",
    ">  <TPSA>\n",
    "37.300\n",
    "\n",
    ">  <RotBonds>\n",
    "1\n",
    "\n",
    "```\n",
    "Sie sehen auch zusätzliche Informationen wie TPSA oder LogP können gleich mit gespeichert werden.\n",
    "\n",
    "Um so eine `.sdf` Datei in Python einzulesen, brauchen wir einen sogenannten `MolSupplier` von `rdkit`. Ein Supplier stellt die Verbindung zwischen unsere Datein und Python her. Mit einem `for-loop` können dann die einzelnen Smiles aus dem SDF-File gelesen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppl = Chem.SDMolSupplier(\"../data/high_fidelity/fragments.sdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = []\n",
    "for mol in suppl:\n",
    "    smiles.append(Chem.MolToSmiles(mol)) \n",
    "smiles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbfa9c",
   "metadata": {},
   "source": [
    "Wie Sie sehen, ist dies eine weitere Möglichkeit, aus den `.sdf`-Dateien Smiles zu erzeugen.\n",
    "\n",
    "Außerdem können wir die Strukturen einmal anzeigen, um ein besseres Gefühl für die Art der Fragmente zu bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1984e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MolsToGridImage([Chem.MolFromSmiles(x)for x in smiles[:9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb44b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5619c39e",
   "metadata": {},
   "source": [
    "Insgesamt haben wir 1675 Moleküle im Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73af29b3",
   "metadata": {},
   "source": [
    "Wenn Sie sich die Smiles genau ansehen, fällt Ihnen dann etwas auf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70b608",
   "metadata": {},
   "source": [
    "Ein Problem ist, dass die Stereoinformationen immer noch in den Smiles enthalten sind. Zum Beispiel das `@`-Symbol. Ein weiteres Problem ist das `.`. Dieses markiert den Beginn eines weiteren Moleküls. In unserem Fall sind es aber eigentlich nur `Cl`-Atome, die sich noch in einigen Smiles befinden. \n",
    "Zum Beispiel die Moleküle 61."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642e7ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(smiles[60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547f368",
   "metadata": {},
   "source": [
    "Wir können die Stereoinformationen sowie die \"zusätzlichen\" Moleküle durch String-Manipulationen entfernen.\n",
    "\n",
    "`string.replace(\"@\", \"\")`\n",
    "\n",
    "durchsucht den `string` nach dem Zeichen `@` und wenn es eines findet, werden sie durch `\"\"` ersetzt, werden also einfach entfernt.\n",
    "\n",
    "\n",
    "*Alternativ kann auch folgender Code benutzt werden:*\n",
    "\n",
    "```python\n",
    "Chem.MolToSmiles(Chem.MolFromSmiles(\"N[C@@H](C)C(=O)O\"),isomericSmiles=False)\n",
    "```\n",
    "Die option `isomericSmiles = False` wurde erst später zu RDKit hinzugefügt.\n",
    "\n",
    "\n",
    "`string.split(\".\")`\n",
    "\n",
    "teilt den `string` an jedem `\".\"` auf. Die Funktion gibt die einzelnen Teilstrings als Liste aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35edf4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Schoko.l@de\".replace(\"@\", \"\").split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07972f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_molecules = []\n",
    "for smile in smiles:\n",
    "    smile = smile.replace(\"@\", \"\")\n",
    "    smile = smile.replace(\"\\\\\", \"\")\n",
    "    sub_molecules.append(smile.split(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e7da1",
   "metadata": {},
   "source": [
    "Im nächsten Schritt müssen wir nur noch die Moleküllisten durchgehen. Wenn ein Smiles aus mehreren Molekülen besteht, wählen wir einfach das größte Molekül als das richtige aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97a07d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered_smiles =[]\n",
    "for mol_list in sub_molecules:\n",
    "    filtered_smiles.append(mol_list[np.argmax([len(x) for x in mol_list])])\n",
    "    \n",
    "Chem.MolFromSmiles(filtered_smiles[60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b429d79",
   "metadata": {},
   "source": [
    "Das 61ste Moleküle beinhaltet jetzt nicht mehr das zusätzlichen `HCl`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bac998",
   "metadata": {},
   "source": [
    "Die Smiles sind nun \"sauber\" und wir können damit beginnen, sie für das RNN vorzubereiten. Erstellen Sie also einen Dictionary und ersetzen Sie die Smiles durch Tokens. Zuerst verwenden wir wieder die Funktion `creat_dict`, um ein Dictionery für unsere Daten zu erstellen. Aber dieses Mal verwenden wir auch den Parameter `add_tokens = True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047333c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary = create_dict(filtered_smiles, add_tokens =True)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4917b",
   "metadata": {},
   "source": [
    "Es wurden 3 neue Tokens hinzugefügt, die in den Smiles nicht vorkommen.\n",
    "\n",
    "- Sie kennen bereits `<pad>`. Er wird verwendet, um alle Smiles auf die gleiche Länge zu bringen.\n",
    "\n",
    "- `<sos>` ist ein Token, der den Beginn eines Smiles ankündigt. \"Start of Sentence\". Dieses Token wird **vor** jeden Smiles gesetzt.\n",
    "\n",
    "- `<eos>` zeigt das Ende des Smiles an. Nachdem der eigentliche Smiles vorbei ist, folgt der Token `<eos>` und dann die Padding Token.\n",
    "\n",
    "Alle unsere Smiles sollten also wie folgt aussehen:\n",
    "\n",
    "```python\n",
    "\"<sos>OCc1ccc2occc2c1<eos><pad><pad>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bb0b0",
   "metadata": {},
   "source": [
    "\n",
    "Warum ist das notwendig? Warum werden diese speziellen Token benötigt?\n",
    "\n",
    "Das liegt daran, wie ein Decoder in einem RNN funktioniert. \n",
    "\n",
    "Noch einmal zur Erinnerung: So sieht unser Modell aus:\n",
    "\n",
    "<img src=\"Img/rnn/auto_1.png\" width =\"400px\">\n",
    "\n",
    "Den Encoder haben wir quasi letzte Woche geschrieben, jetzt müssen wir uns nur noch auf den Decoder konzentrieren.\n",
    "Die Grundidee eines Decoder-RNN ist, dass die SMILES Token für Token nacheinander erzeugt werden.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "Der Decoder erhält den latenten Vektor vom Encoder:\n",
    "Darauf erzeugt er ein `C`. Nun kann der Decoder mit Hilfe des latenten Vektors und des bereits erzeugten `C` ein weiteres `C` erzeugen. Dann ist unser aktueller Smiles `CC`. Nun wird der Schritt noch einmal wiederholt, mit dem Wissen des latenten Vektors und den bereits zwei `CC`.\n",
    "Jetz kann der Decoder  z.B. ein `=` erzeugen: `CC=` usw...\n",
    "Theoretisch könnte dies unendlich so weitergehen. Deshalb gibt es ein `<eos>`-Token. Dieses Token erlaubt es dem Netzwerk, den Smiles zu beenden, wenn es denkt, dass dieser komplett ist.\n",
    "\n",
    "Im Folgenden wird es ein wenig theoretischer:\n",
    "\n",
    "Um es genauer zu verstehen, wiederholen wir kurz, wie ein RNN funktioniert.\n",
    "\n",
    "Ein RNN hat immer zwei Inputs. Einer ist die normale Eingabe, d.h. das aktuelle Token (Smile-Symbol), für das eine Vorhersage gemacht werden muss.\n",
    "Zusätzlich wird ein Hidden State aus dem vorherigen Schritt übernommen. Also die Ausgabe des RNN für den vorherige Token.\n",
    "\n",
    "Durch den Encoder erhalten wir bereits den latenten Vektor, der unser anfänglicher Hidden State für den Decoder sein wird. \n",
    "\n",
    "<img src=\"Img/rnn/auto_3.png\" width =\"400px\">\n",
    "\n",
    "Doch was ist unser initialer Input?\n",
    "\n",
    "<img src=\"Img/rnn/auto_4.png\" width =\"400px\">\n",
    "\n",
    "Das Problem ist, wenn wir den tatsächlich ersten Token des originalen Smiles als ersten Token für den Decoder verwenden, ist es relativ leicht diesen richtig zu vorhersagen. Deshalb verwenden wir zuerst den Token `<sos>` als ersten Input für den Decoder. Dieses Token enthält keine Informationen über den Inputsmiles. Das heißt, der erste Token wird nur auf der Grundlage des Hidden State oder dem latent Vektor vorhergesagt. Wichtig ist auch, dass die Ausgabe des RNN (der neue Hidden State) zunächst eine lineare Schicht durchläuft, die dann den richtigen Token vorhersagt.\n",
    "<img src=\"Img\\rnn\\auto_6.png\" width =\"400px\">\n",
    "\n",
    "Im nächsten Schritt ersetzt der neue Hidden State den latent Vektor als Input für den nächsten Schritt. Auch wird nicht mehr ein Token des ursprünglichen Smile als Input verwendet, sondern der Token, der im vorherigen Schritt vorhergesagt wurde. \n",
    "Das heißt, selbst wenn der Decoder am Anfang einen Fehler macht, rechnet er mit diesem Fehler weiter.\n",
    "<img src=\"Img\\rnn\\auto_7.png\" width =\"400px\">\n",
    "\n",
    "Wir wiederholen dies, bis wir die Länge des längsten Smiles in unserem Datensatz erreicht haben. Natürlich sind die meisten Smiles nicht so lang, also können wir den `<eos>` Token verwenden. Damit kann der Smiles vorher beendet werden. \n",
    "<img src=\"Img/rnn/auto_8.png\" width =\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760abc3c",
   "metadata": {},
   "source": [
    "Wenn wir in der Funktion `tokenize` ` (..., add_tokens=True)` verwenden, werden `<sos>` und `<eos>` automatisch zu jedem Smile hinzugefügt. Die `0` steht im `dictionary` für `<sos>` und die `1` für `<eos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_smiles = tokenize(filtered_smiles,dictionary, add_tokens =True)\n",
    "tokenized_smiles[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157fd4b",
   "metadata": {},
   "source": [
    "Die Smiles sind immer noch alle unterschiedlich lang. Wir berechnen zunächst die Anzahl der Token in jedem Smiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba76b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lengths = np.array([len(x) for x in tokenized_smiles])\n",
    "max_length=max(token_lengths)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d941b",
   "metadata": {},
   "source": [
    "Wir können die Anzahl der Token auch mit einem Histogramm darstellen. Das Problem ist, je mehr Token ein Smiles hat, desto schwieriger ist es für den Decoder, den komplette Smiles wiederherzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b22d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(token_lengths, bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df0d1f",
   "metadata": {},
   "source": [
    "Wir könnten zum Beispiel alle Moleküle aus dem Datensatz herauswerfen, die aus mehr als 26 Token bestehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(token_lengths>26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16c132",
   "metadata": {},
   "source": [
    "Das sind genau 232 Moleküle. Das ist natürlich nicht ideal, aber es hilft uns beim Training. Gerade mit so wenigen Daten ist es schwierig, einen Autoencoder zu trainieren. Wir entfernen diese Moleküle dennoch aus dem Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da40f8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_smiles=np.array(filtered_smiles)[token_lengths<=26].tolist()\n",
    "len(filtered_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c326e3a",
   "metadata": {},
   "source": [
    "Mit den reduzierten Daten erstellen wir einen neuen Dictionary und tokenisieren unsere Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ef97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = create_dict(filtered_smiles, add_tokens =True)\n",
    "tokenized_smiles = tokenize(filtered_smiles,dictionary, add_tokens =True)\n",
    "tokenized_smiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lengths = np.array([len(x) for x in tokenized_smiles])\n",
    "max_length=max(token_lengths)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decca5bc",
   "metadata": {},
   "source": [
    "Alle unsere Smiles bestehen nun aus maximal 26 Zeichen. In einem letzten Schritt müssen wir die Smiles, die nicht aus 26 Tokens bestehen, auf die richtige Länge bringen. Dazu verwenden wir das `<pad>`-Token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cdfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tok_smi in enumerate(tokenized_smiles):\n",
    "    tokenized_smiles[i] = tok_smi+ [dictionary[\"<pad>\"]]*(max_length - token_lengths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c6cde",
   "metadata": {},
   "source": [
    "Im letzten Schritt wandeln wir die Listen der Tokens in einen `tensor` um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09693c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_smiles=torch.tensor(tokenized_smiles, dtype=torch.long)\n",
    "tokenized_smiles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c342b",
   "metadata": {},
   "source": [
    "## Modell\n",
    "\n",
    "Heute werden wir nicht `nn.Sequential`  verwenden, um unser Modell zu erstellen. Für einfache Architekturen bietet sich `nn.Sequential` an. Allerdings ist es nicht sehr flexibel. \n",
    "Deshalb werden die meisten Netzwerke in PyTorch \"von Hand\" geschrieben.\n",
    "\n",
    "Wie das gemacht wird, wollen wir uns heute ansehen:\n",
    "\n",
    "Es gibt zwei Prozesse, die ein Netzwerk in PyTorch eigentlich immer ausführen muss:\n",
    "\n",
    "1. es muss die notwendigen Weights initialisieren \n",
    "2. es muss den Input durch das Netz leiten\n",
    "\n",
    "Die Initialisierung bei `nn.Sequential()` wird automatisch bei der Erstellung des Modells durchgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(10,20), nn.ReLU(), nn.Dropout(0.2), nn.Linear(20,1))\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa79a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1a0ab",
   "metadata": {},
   "source": [
    "Auf diese Weise haben wir unsere Netze bisher definiert. Jede Layer ist automatisch\n",
    "erstellt und die Weights zufällig initialisiert.\n",
    "\n",
    "Wir können aber auch unser eigenes Netzwerk selbst definieren.\n",
    "Dazu müssen wir eine PyTorch-Klasse erstellen. Klassen in Python sind ähnlich wie Funktionen. Nur können Klassen auch Eigenschaften und eigene Funktionen enthalten. Wir werden hier nicht auf die genauen Funktionalitäten von Klassen eingehen.\n",
    "\n",
    "Wichtig ist nur, dass wir auch Klassen erstellen können, die sich wie PyTorch-Klassen verhalten.\n",
    "Dazu schreiben wir zunächst den folgenden Code:\n",
    "\n",
    "``` python\n",
    "class einfaches_nn(nn.Module):\n",
    "```\n",
    "\n",
    "\n",
    "Damit legen wir fest, dass die Klasse `einfaches_nn` eine Klasse ist, die zu `nn.Module` gehört. Wie andere Layers oder Modelle in PyTorch sollte sie also zu `nn` gehören bzw. ähnlich funktionieren.\n",
    "\n",
    "Als nächstes kommt die Initialisierung \n",
    "\n",
    "``` python\n",
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "```\n",
    "\n",
    "`def __init__(self,input_dim, hid_dim, out_dim, dropout):` ist eine Funktion, die bei der Initialisierung des Netzes aufgerufen wird. Also zum Beispiel `model = einfaches_nn`. Automatisch wird dann ausgeführt was in der `__init__` Funktion steht. Es ist wichtig, dass neben den Dimensionen, die die Größe des Netzes bestimmen, auch ein `self` als Input angegeben wird.\n",
    "\n",
    "`self` \"enthält\" alle Informationen, die für diese Klasse gespeichert werden (sollen). Diese können auch über die Funktion hinaus benutzt werden. Das sollte in ein paar Minuten deutlicher werden.\n",
    "\n",
    "`super().__init__()` ist Teil des Codes der wichtig für PyTorch Klassen ist. Dieser Teil darf nicht in der Initialisierung fehlen.\n",
    "\n",
    "Als Nächstes können wir unsere linear Layers und Dropout in `self` \"speichern\":\n",
    "\n",
    "``` python\n",
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "```\n",
    "\n",
    "`self.ln1 = nn.Linear(input_dim, hid_dim)` erlaubt es uns, später in andere Funktionen die erste linear Layer mit `self.ln1` auszuwählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a67e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84193b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_2 = einfaches_nn(input_dim=10,hid_dim= 20, out_dim=1, dropout=0.2)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59106e34",
   "metadata": {},
   "source": [
    "Wir können sehen, dass das Netz auch aus den richtigen Layers besteht, aber in der falschen Reihenfolge. Auch die ReLU-Funktion fehlt. Das ist bisher nicht weiter schlimm, denn die Funktion `__init__` soll das Modell nur initialisieren, also nur die Schichten und deren Weights erzeugen. ReLU hat keine Gewichte und muss daher nicht \"initialisiert\" werden.\n",
    "\n",
    "Hier ist auch der Beweis, dass das Netzwerk `Modell_2` jetzt zufällige Weights hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4981a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(model_2.parameters())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f22545",
   "metadata": {},
   "source": [
    "Wir können auch probieren, ob die Model von einem Input (`fake_input` enthält zufällige Zahlen) einen Output generieren kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_input = (torch.rand(10))\n",
    "\n",
    "model(fake_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8358ba25",
   "metadata": {},
   "source": [
    "Für das `nn.Sequential` Modell kein Problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75736a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_input = (torch.rand(10))\n",
    "\n",
    "model_2(fake_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e2818a",
   "metadata": {},
   "source": [
    "Der Fehler \n",
    "```python\n",
    "raise NotImplementedError\n",
    "```\n",
    "wird ausgegeben. Das bedeutet, dass wir diesen Teil des Modells noch nicht implementiert haben, d.h. wir haben ihn noch nicht in der Klasse definiert.\n",
    "\n",
    "Bis jetzt kann `simple_nn` nur die Weights initialisieren. Aber es weiß noch nicht, wie es die Inputs durch das Netz leiten soll.\n",
    "In `nn.Sequential` wird dies automatisch gemacht. Der Input wird einfach nacheinander durch die Layer geleitet. Die Reihenfolge ergibt sich aus der Reihenfolge dieser Layers bei der Initialisierung. \n",
    "\n",
    "Damit das für unsere eigene Klasse funktioniert, benötigen wir eine weitere Funktion namens \n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "`forward` ist, wie der Name andeutet, für die Forward Propagation zuständig. Es legt fest in welcher Reihnfolge Input `x` durch die zuvor definierten Layers geführt wird.\n",
    "Es ist auch wichtig zu beachten, dass `self` ein weiterer Input neben `x` ist. `self` enthält alle Informationen, die wir bereits in `__ìnit__` definiert haben.\n",
    "\n",
    "```python\n",
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        output = self.ln2(x)\n",
    "        return output\n",
    "```\n",
    "\n",
    "\n",
    "Hier geben wir Schritt für Schritt an, was mit dem ursprünglichen Input passieren soll. Im ersten Schritt wird `x` durch die erste lineare Layer geführt. Diese wurde in `self.ln1` gespeichert. Nur für die Aktivierungsfunktion brauchen wir `self` nicht, da diese auch nicht initialisiert wurde.\n",
    "\n",
    "---\n",
    "**Wichtig ist auch, dass wir jetzt nicht mehr** `nn.ReLU` **verwenden können, sondern wir müssen** `.nn.functional.relu()` **benutzen.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad426321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        output = self.ln2(x)\n",
    "        return output\n",
    "    \n",
    "model_2 = einfaches_nn(input_dim=10,hid_dim= 20, out_dim=1, dropout=0.2)\n",
    "model_2    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39badb3",
   "metadata": {},
   "source": [
    "An der Initialisierung hat sich nichts geändert, aber wir können jetzt Input durch das Netzwerk führen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2(fake_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7113cf5",
   "metadata": {},
   "source": [
    "Wir können also komplexere Netzwerke designen, die nicht nur einen Input haben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c968a",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "Nun zurück zu unserem Autoencoder.\n",
    "Zuerst definieren wir den Encoder.\n",
    "Wir haben eine `nn.Embedding` Layer und eine `nn.GRU` Layer. Der Encoder ist genau so aufgebaut wie das RNN im letzten Notebook, nur dass wir das Netzwerk hier explizit selbst schreiben.\n",
    "\n",
    "Sehen Sie sich die Funktion `forward` an. Als Input nimmt sie eine `input_seq`, das ist eine Folge von Tokens. Die Output ist der letzte `hidden` State des Netzes. Dieser beschreibt den komplette Smiles und ist gleichzeitig unser latenter Vektor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0275fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim) \n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.dropout(self.embedding(input_seq))\n",
    "        outputs, hidden = self.rnn(embedded) \n",
    "        return hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017de72c",
   "metadata": {},
   "source": [
    "## Decoder \n",
    "\n",
    "Der Decoder ist schon etwas komplexer.  Wenn Sie nicht den gesamten Code verstehen, ist das in Ordnung. Solange Sie dem allgemeinen Konzept folgen können.\n",
    "Wieder haben wir eine `Embedding` Layer und eine `GRU` Layer, zusätzlich gibt es noch eine Linear Layer. Diese bestimmt anhand des Hidden States welcher Token generiert werden soll.\n",
    "\n",
    "Im `forward` Pass gibt es zwei Inputs. Einmal den `input`, das ist der letzte Token, der vorhergesagt wurde. Am Anfang ist das der`<sos>` Token. `hidden` ist der Hidden State des `GRU` aus dem vorherigen Schritt.\n",
    "`forward` gibt sowohl die `prediction`, der vorhergesagte Token, als auch `hidden`, den neuen Hidden State, aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        prediction = self.fc_out(output[0])\n",
    "        \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78160a22",
   "metadata": {},
   "source": [
    "Schließlich führen wir beide Komponenten in einem `Autoencoder` zusammen. Als Input nimmt dieses Modell einen Decoder und einen Encoder.  Der Autoencoder hat auch seinen eigenen `forward` Pass. Zunächst wird der Input durch den Encoder geschickt. Der Encoder gibt uns den Hidden State `hidden`. Dieser Hidden State wird dann einmal zu Beginn des `for-loops` für den Decoder verwendet. Außerdem nehmen wir die erste Zeile von `output_seq` als erste Input für den Decoder. Diese Zeile besteht aus den `<sos>`-Tokens.\n",
    "\n",
    "Wir verwenden auch Teacher Forcing. Teacher Forcing wird beim Training verwendet, um es dem Decoder zu erleichtern, den vollständigen Smiles wiederherzustellen. Wenn der Decoder einen falschen Token am Anfang eines Smiles vorschlägt, muss der Decoder mit diesem falschen Token als Input  weiterrechnen. Dies kann vor allem zu Beginn des Trainings ein Problem darstellen, da hier viele Fehler gemacht werden. Durch Teacherforcing wird der vorhergesagten Token durch den richtigen Token ersetzt. So kann der Decoder mit dem richtigen Token weiterrechnen. Bei der Evaluierung wird das Teacher-Forcing dann ausgeschaltet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        \n",
    "    def forward(self, input_seq, output_seq, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        # speichern von Parametern\n",
    "        batch_size = output_seq.shape[1]\n",
    "        trg_len = output_seq.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size)\n",
    "        \n",
    "        \n",
    "        # Eigentlicher Forward Pass\n",
    "        \n",
    "        # Der Encoder berechnet den Hidden State/Latent Vector\n",
    "        hidden = self.encoder(input_seq)\n",
    "        \n",
    "        # Als initialen Input für den Decoder wählen wir die <sos> Tokens aus\n",
    "        input = output_seq[0,:]\n",
    "        \n",
    "        # Der for-loop wird benutzt, um nacheinander die Tokens zu generieren.\n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            top1 = output.argmax(1) \n",
    "\n",
    "            input = output_seq[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c8ed2",
   "metadata": {},
   "source": [
    "Wie gegesagt, es ist okay wenn Sie in diesem Fall nicht alles verstehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966af5d2",
   "metadata": {},
   "source": [
    "Zunächst müssen wir unser Model definieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34add64c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "enc = Encoder(len(dictionary), 128, 256, 0.2)\n",
    "dec = Decoder(len(dictionary),128,256,0.2)\n",
    "model = Autoencoder(enc, dec)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b2133",
   "metadata": {},
   "source": [
    "Man kann deutlich die verschiedenen Komponenten des Autoencoders sehen.\n",
    "Wir erstellen auch noch einen `DataLoader`. Dieser nimmt als $x$ und $y$ die gleiche Sequenz, da wir einen Autoencoder trainieren wollen. Außerdem speichern wir einen Beispielbatch `ex_in` und `ex_out`.\n",
    "\n",
    "Da wir so wenig Daten haben, verwenden wir keinen Testdatensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(tokenized_smiles, tokenized_smiles)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "ex_in = ex_out = tokenized_smiles[:16,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d8fa3",
   "metadata": {},
   "source": [
    "Wir definieren unseren Optimizer und unsere Lossfunktion. Hier können wir auch angeben, dass der Index `2` bei der Berechnung des Loss ignoriert werden soll. Dies ist der Index für den `<pad>` Token. Und dieser ist für die Vorhersage nicht wichtig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b2f2c",
   "metadata": {},
   "source": [
    "Der letzte Schritt ist der Trainingsloop. Dieser ist ein normaler `for-loop`, aber wir verwenden die Transponierung der `input_seq` und der `output_seq`. Denn so gehen die Funktionen der Netze leichter ineinander über. \n",
    "\n",
    "Im Trainingsloop selbst wird die Qualität der generierten Smiles alle 5 Epochen bewertet. Es wird betwertet wie viele Smiles sind gültig und wie viele Smiles sind tatsächloch identisch mit dem Input.\n",
    "\n",
    "Dies geschieht durch die Funktion `evaluate()`, die für Sie vorgeschrieben wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2fac53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for input_seq, output_seq in train_loader:\n",
    "        optimizer.zero_grad()        \n",
    "        \n",
    "        input_seq = input_seq.t()\n",
    "        output_seq = output_seq.t()\n",
    "\n",
    "\n",
    "        output = model(input_seq, output_seq, 0.2)\n",
    "        \n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].reshape(-1, output_dim)\n",
    "        output_seq =  output_seq[1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output,  output_seq)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    if (epoch%5==0):\n",
    "        valid, correct=evaluate(model, train_loader, dictionary)\n",
    "        print(f\"Epoch {epoch}: Loss: {epoch_loss /len(train_loader)} % Valid: {valid.round(2)} % Correct: {correct.round(2)} \")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch}: Loss: {epoch_loss /len(train_loader)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fca008",
   "metadata": {},
   "source": [
    "Jetzt können wir schauen, wie gut unser Model wirklich ist. Während des Trainings benutzen wir immer noch Teacher Forcing. Das wird während der Evaluierung ausgeschaltet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model,train_loader, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06fcdcb",
   "metadata": {},
   "source": [
    "Unser Autoencoder generiert  tatsächlich valide Smiles. Viele der generierten Smiles sind auch tatsächlich identisch zu den Inputsmiles.\n",
    "\n",
    "Autoencoder sind schwierig zu trainieren, besonders für Sprachen oder auch Smiles. Die Grammatik von Smiles muss erst erlernt werden. Dafür brauch es eigentlich viel mehr Daten. Darüber hinaus, benutzen wir ein sehr simples Model. Trotzdem können wir und das Netzwerk ein wenig genauer anschauen.\n",
    "\n",
    "Wir können uns zum Beispiel die Vorhersagen für unseren `ex_in` Batch anschauen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d800d8",
   "metadata": {},
   "source": [
    "Wir lassen uns die vorhergesagten Token für die ersten beide Smiles im Batch aus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0f177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(ex_in.t(), ex_out.t(), 0)\n",
    "pred_tokens =pred.argmax(2).t().detach().numpy()\n",
    "\n",
    "pred_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6254adc7",
   "metadata": {},
   "source": [
    "Zum Vergleich, die Originaldaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b3736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex_out[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd843bf7",
   "metadata": {},
   "source": [
    "Die Funktion `token_to_smiles` wandelt die Token wieder in Smiles um:\n",
    "So sehen die vorhergesagten Smiles aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_smiles = tokens_to_smiles(pred_tokens,dictionary )\n",
    "true_smiles = tokens_to_smiles(ex_out.detach().numpy(), dictionary)\n",
    "pd.DataFrame({\"true\":true_smiles, \"pred\": pred_smiles })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19630902",
   "metadata": {},
   "source": [
    "Tatsächlich sind die meisten Smiles identisch zu dem originalen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48da8a",
   "metadata": {},
   "source": [
    "# Neue Molkeüle generieren\n",
    "\n",
    "Wir haben einen Decoder, der aus unseren Hidden States/latenten Vektoren gültige Moleküle erzeugen kann. \n",
    "Bis jetzt haben wir die latenten Vektoren erhalten, indem wir bekannte Smiles durch den Encoder geschickt haben. Aber was hält uns davon ab, zufällige latente Vektoren zu erzeugen und zu sehen, was der Decoder daraus generiert? Unsere Hidden States latenten Vektoren haben diese Größe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors =  model.encoder(ex_in.t()).detach().numpy()\n",
    "latent_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e13f03",
   "metadata": {},
   "source": [
    "Wir können einfach einen alternativen latenten Vektor `tensor` erstellen. Diesen füllen wir mit zufälligen Zahlen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(5489786)\n",
    "hidden = torch.randn(1,16,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab24ca",
   "metadata": {},
   "source": [
    "Wir verwenden diesen anstelle des ursprünglichen`tensors` als Input für den Decoder.\n",
    "Der Decoder sollte nun versuchen, aus diesen Zufallsdaten neue Smiles zu generieren. Da der Hidden State zufällig gewählt wurde, sollte es sich um Moleküle handeln, die noch nicht in unserem Datensatz enthalten sind. Man spricht in solchen Fällen von De-Novo Design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0563cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.zeros(26, 16, len(dictionary))\n",
    "input_ = ex_out.t()[0,:] #<- [\"<sos>\"] Tokens\n",
    "for t in range(1, 26):\n",
    "    output, hidden = model.decoder(input_, hidden)\n",
    "    outputs[t] = output\n",
    "    input_ = output.argmax(1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce9de3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_tokens = outputs.argmax(2).t().detach().numpy()\n",
    "new_smiles = tokens_to_smiles(pred_tokens, dictionary)\n",
    "new_smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f51e52",
   "metadata": {},
   "source": [
    "Tatsächlich ist keines dieser Moleküle in unserem Datensatz enthalten. Das liegt aber vorallem daran das die meisten keine gültige Moleküle sind. \n",
    "Das Problem besteht hauptsächlich darin, dass der latente Raum, d. h. der gesamte Raum, der durch unsere latenten Vektoren beschrieben werden kann, viel zu groß ist. Es wird sehr schwierig sein, zufällig Zahlen zu finden, die ein gültiges Molekül ergeben.\n",
    "\n",
    "Um wirklich effektiv Moleküle mit Hilfe von Autoencodern zu erzeugen, benötigen wir viel mehr Daten. So kann die Grammatik der Smiles besser gelernt werden. Auch werden am häufigsten so genannte Variational-Autoencoder (VAE) verwendet. Diese \"zwingen\" den latenten Raum in einen vordefinierten Raum. Wenn man dann Zufallszahlen wählt, die denselben definierten Raum entsprechen, ist die Wahrscheinlichkeit höher, dass es sich um ein gültiges Molekül handelt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62529bf",
   "metadata": {},
   "source": [
    "# Übungsaufgabe\n",
    "\n",
    "In der heutigen Übung geht es nicht um Autoencoders. Die Aufgabe besteht darin, ein `nn.Sequential`-Modell in eine funktionierende PyTorch-Klasse umzuschreiben.\n",
    "\n",
    "Das Modell sieht wie folgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ecb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit import RDLogger  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "RDLogger.DisableLog('rdApp.*')      \n",
    "%run ../utils/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6f7ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_1 =nn.Sequential(nn.Linear(20,100),\n",
    "              nn.BatchNorm1d(100),\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(0.2),\n",
    "              nn.Linear(100,100),\n",
    "              nn.BatchNorm1d(100),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(100,10))\n",
    "model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d5884",
   "metadata": {},
   "source": [
    "Schreiben Sie das Modell um. Beachten Sie, dass `nn.ReLU` nicht in `forward` funktioniert. Hier verwenden Sie bitte `nn.functional.relu()`. Es ist auch wichtig zu wissen, dass `__init__` so viele Inputparameter haben kann, wie Sie wollen, sie können zum Beispiel die `__init__` so schreiben:\n",
    "`__init__(self, input_dim, hid1_dim, hid2_dim, ________)`, um mehrere Hidden Layers zu initialisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4da2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class simple_nn(________):\n",
    "    def __init__(self, ___________________________________________):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = simple_nn(______________________________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7c204",
   "metadata": {},
   "source": [
    "Testen Sie, ob ihr Modell einen Output generiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(213)\n",
    "test_data = torch.randn(100,20)\n",
    "\n",
    "model_2(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25431735",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
